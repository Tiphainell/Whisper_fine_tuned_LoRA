Running via sbatch on puck5 on Wed Oct 15 09:52:37 AM CEST 2025
Python 3.10.13
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Appending key for api.wandb.ai to your netrc file: /home/tleludec/.netrc
wandb: Currently logged in as: tiphaine-leludec (tiphaine-leludec-ens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 52wmt7zc
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/wandb/run-20251015_095256-52wmt7zc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-dream-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tiphaine-leludec-ens/whisper_lora
wandb: üöÄ View run at https://wandb.ai/tiphaine-leludec-ens/whisper_lora/runs/52wmt7zc
trainable params: 491,520 || all params: 1,543,796,480 || trainable%: 0.0318
  0%|          | 0/8319 [00:00<?, ?it/s]/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.
  warnings.warn(
You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|          | 1/8319 [00:10<24:16:13, 10.50s/it]  0%|          | 2/8319 [00:17<18:56:05,  8.20s/it]  0%|          | 3/8319 [00:23<16:56:47,  7.34s/it]  0%|          | 4/8319 [00:29<15:38:53,  6.77s/it]  0%|          | 5/8319 [00:35<15:02:22,  6.51s/it]  0%|          | 6/8319 [00:42<15:32:25,  6.73s/it]  0%|          | 7/8319 [00:48<14:56:39,  6.47s/it]  0%|          | 8/8319 [00:55<15:21:16,  6.65s/it]  0%|          | 9/8319 [01:01<15:13:17,  6.59s/it]  0%|          | 10/8319 [01:08<15:18:17,  6.63s/it]/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py:43: UserWarning: [SKIP] Erreur de lecture pour /scratch1/data/raw_data/HD_PARK_HOSPITAL/audio/MICRO3/4CH025M.wav : Error opening '/scratch1/data/raw_data/HD_PARK_HOSPITAL/audio/MICRO3/4CH025M.wav': Format not recognised.
  warnings.warn(f"[SKIP] Erreur de lecture pour {audio_path} : {e}")
  0%|          | 11/8319 [01:14<15:01:31,  6.51s/it]  0%|          | 12/8319 [01:22<15:44:57,  6.83s/it]  0%|          | 13/8319 [01:28<15:26:26,  6.69s/it]  0%|          | 14/8319 [01:35<15:34:54,  6.75s/it]  0%|          | 15/8319 [01:43<16:28:03,  7.14s/it]  0%|          | 16/8319 [01:49<15:49:47,  6.86s/it]  0%|          | 17/8319 [01:57<16:35:39,  7.20s/it]  0%|          | 18/8319 [02:04<16:04:32,  6.97s/it]  0%|          | 19/8319 [02:11<16:23:45,  7.11s/it]  0%|          | 20/8319 [02:18<16:14:37,  7.05s/it]  0%|          | 21/8319 [02:25<15:43:08,  6.82s/it]  0%|          | 22/8319 [02:31<15:15:00,  6.62s/it]  0%|          | 23/8319 [02:37<15:20:18,  6.66s/it]  0%|          | 24/8319 [02:44<15:19:01,  6.65s/it]  0%|          | 25/8319 [02:52<16:01:13,  6.95s/it]  0%|          | 26/8319 [02:59<16:19:08,  7.08s/it]  0%|          | 27/8319 [03:07<16:34:21,  7.20s/it]  0%|          | 28/8319 [03:13<16:12:45,  7.04s/it]  0%|          | 29/8319 [03:20<15:53:53,  6.90s/it]  0%|          | 30/8319 [03:26<15:34:29,  6.76s/it]  0%|          | 31/8319 [03:33<15:16:46,  6.64s/it]  0%|          | 32/8319 [03:40<15:28:42,  6.72s/it]  0%|          | 33/8319 [03:47<15:51:51,  6.89s/it]  0%|          | 34/8319 [03:54<16:08:52,  7.02s/it]  0%|          | 35/8319 [04:00<15:18:56,  6.66s/it]  0%|          | 36/8319 [04:07<15:48:34,  6.87s/it]  0%|          | 37/8319 [04:14<15:36:24,  6.78s/it]  0%|          | 38/8319 [04:21<15:44:53,  6.85s/it]  0%|          | 39/8319 [04:27<15:18:07,  6.65s/it]  0%|          | 40/8319 [04:33<14:56:21,  6.50s/it]  0%|          | 41/8319 [04:39<14:23:32,  6.26s/it]  1%|          | 42/8319 [04:46<14:48:34,  6.44s/it]  1%|          | 43/8319 [04:52<14:49:09,  6.45s/it]  1%|          | 44/8319 [04:59<14:56:21,  6.50s/it]  1%|          | 45/8319 [05:06<15:16:26,  6.65s/it]  1%|          | 46/8319 [05:13<15:23:11,  6.70s/it]  1%|          | 47/8319 [05:19<14:55:45,  6.50s/it]  1%|          | 48/8319 [05:25<14:37:18,  6.36s/it]  1%|          | 49/8319 [05:32<14:53:17,  6.48s/it]  1%|          | 50/8319 [05:39<15:14:21,  6.63s/it]                                                      1%|          | 50/8319 [05:39<15:14:21,  6.63s/it]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.
Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
{'loss': 2.7376, 'grad_norm': 0.5404665470123291, 'learning_rate': 0.0009941098689746364, 'epoch': 0.02}
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']

  0%|          | 0/895 [00:00<?, ?it/s][A
  0%|          | 2/895 [00:26<3:18:58, 13.37s/it][A
  0%|          | 3/895 [00:43<3:41:12, 14.88s/it][A
  0%|          | 4/895 [01:14<5:10:23, 20.90s/it][A
  1%|          | 5/895 [01:33<5:00:06, 20.23s/it][A
  1%|          | 6/895 [02:00<5:33:30, 22.51s/it][A
  1%|          | 7/895 [02:29<6:01:02, 24.39s/it][A
  1%|          | 8/895 [02:55<6:09:22, 24.99s/it][A
  1%|          | 9/895 [03:09<5:21:02, 21.74s/it][A
  1%|          | 10/895 [03:24<4:46:57, 19.45s/it][A
  1%|          | 11/895 [03:41<4:36:03, 18.74s/it][A
  1%|‚ñè         | 12/895 [03:54<4:10:27, 17.02s/it][A
  1%|‚ñè         | 13/895 [04:10<4:04:05, 16.60s/it][A
  2%|‚ñè         | 14/895 [04:26<4:02:45, 16.53s/it][A
  2%|‚ñè         | 15/895 [04:48<4:28:34, 18.31s/it][A
  2%|‚ñè         | 16/895 [05:00<4:00:38, 16.43s/it][A
  2%|‚ñè         | 17/895 [05:18<4:04:34, 16.71s/it][A
  2%|‚ñè         | 18/895 [05:34<4:00:38, 16.46s/it][A
  2%|‚ñè         | 19/895 [05:52<4:08:55, 17.05s/it][A
  2%|‚ñè         | 20/895 [06:11<4:15:38, 17.53s/it][A
  2%|‚ñè         | 21/895 [06:28<4:14:31, 17.47s/it][A
  2%|‚ñè         | 22/895 [06:44<4:09:02, 17.12s/it][A
  3%|‚ñé         | 23/895 [07:02<4:10:48, 17.26s/it][A
  3%|‚ñé         | 24/895 [07:23<4:27:25, 18.42s/it][A
  3%|‚ñé         | 25/895 [07:43<4:33:32, 18.87s/it][A
  3%|‚ñé         | 26/895 [07:56<4:07:23, 17.08s/it][A
  3%|‚ñé         | 27/895 [08:14<4:10:38, 17.33s/it][A
  3%|‚ñé         | 28/895 [08:31<4:08:57, 17.23s/it][A
  3%|‚ñé         | 29/895 [09:00<4:58:52, 20.71s/it][A
  3%|‚ñé         | 30/895 [09:14<4:32:53, 18.93s/it][A
  3%|‚ñé         | 31/895 [10:59<10:43:27, 44.69s/it][A
  4%|‚ñé         | 32/895 [11:16<8:41:14, 36.24s/it] [A
  4%|‚ñé         | 33/895 [11:28<6:58:23, 29.12s/it][A
  4%|‚ñç         | 34/895 [11:41<5:48:28, 24.28s/it][A
  4%|‚ñç         | 35/895 [11:59<5:19:05, 22.26s/it][A
  4%|‚ñç         | 36/895 [12:17<5:02:58, 21.16s/it][A
  4%|‚ñç         | 37/895 [12:27<4:10:59, 17.55s/it][A
  4%|‚ñç         | 38/895 [12:41<3:57:10, 16.60s/it][A
  4%|‚ñç         | 39/895 [14:23<10:03:53, 42.33s/it][A
  4%|‚ñç         | 40/895 [14:33<7:42:47, 32.48s/it] [A
  5%|‚ñç         | 41/895 [14:49<6:33:50, 27.67s/it][A
  5%|‚ñç         | 42/895 [15:13<6:17:50, 26.58s/it][A
  5%|‚ñç         | 43/895 [15:28<5:27:25, 23.06s/it][A
  5%|‚ñç         | 44/895 [17:15<11:22:28, 48.12s/it][A
  5%|‚ñå         | 45/895 [17:31<9:05:49, 38.53s/it] [A
  5%|‚ñå         | 46/895 [17:46<7:27:53, 31.65s/it][A
  5%|‚ñå         | 47/895 [18:00<6:11:21, 26.28s/it][A
  5%|‚ñå         | 48/895 [18:18<5:33:00, 23.59s/it][A
  5%|‚ñå         | 49/895 [18:32<4:54:36, 20.89s/it][A
  6%|‚ñå         | 50/895 [18:47<4:29:18, 19.12s/it][A
  6%|‚ñå         | 51/895 [19:04<4:20:43, 18.53s/it][A
  6%|‚ñå         | 52/895 [19:23<4:21:14, 18.59s/it][A
  6%|‚ñå         | 53/895 [19:38<4:05:55, 17.52s/it][A
  6%|‚ñå         | 54/895 [19:53<3:54:48, 16.75s/it][A
  6%|‚ñå         | 55/895 [20:06<3:40:45, 15.77s/it][A
  6%|‚ñã         | 56/895 [20:25<3:50:15, 16.47s/it][A
  6%|‚ñã         | 57/895 [20:43<3:58:30, 17.08s/it][A
  6%|‚ñã         | 58/895 [20:57<3:45:02, 16.13s/it][A
  7%|‚ñã         | 59/895 [21:14<3:50:24, 16.54s/it][A
  7%|‚ñã         | 60/895 [21:29<3:41:58, 15.95s/it][A
  7%|‚ñã         | 61/895 [21:44<3:37:58, 15.68s/it][A
  7%|‚ñã         | 62/895 [23:29<9:50:12, 42.51s/it][A
  7%|‚ñã         | 63/895 [23:47<8:07:20, 35.14s/it][A
  7%|‚ñã         | 64/895 [24:06<6:59:45, 30.31s/it][A
  7%|‚ñã         | 65/895 [25:51<12:08:21, 52.65s/it][A
  7%|‚ñã         | 66/895 [26:05<9:26:57, 41.03s/it] [A
  7%|‚ñã         | 67/895 [26:27<8:05:56, 35.21s/it][A
  8%|‚ñä         | 68/895 [26:45<6:54:45, 30.09s/it][A
  8%|‚ñä         | 69/895 [26:59<5:47:38, 25.25s/it][A
  8%|‚ñä         | 70/895 [27:13<5:03:08, 22.05s/it][A
  8%|‚ñä         | 71/895 [28:58<10:43:22, 46.85s/it][A
  8%|‚ñä         | 72/895 [30:43<14:40:36, 64.20s/it][A
  8%|‚ñä         | 73/895 [30:56<11:10:04, 48.91s/it][A
  8%|‚ñä         | 74/895 [31:12<8:53:06, 38.96s/it] [A
  8%|‚ñä         | 75/895 [31:27<7:15:12, 31.84s/it][A
  8%|‚ñä         | 76/895 [31:41<6:02:08, 26.53s/it][A
  9%|‚ñä         | 77/895 [31:59<5:25:04, 23.84s/it][A
  9%|‚ñä         | 78/895 [32:15<4:54:32, 21.63s/it][A
  9%|‚ñâ         | 79/895 [32:26<4:11:15, 18.47s/it][A
  9%|‚ñâ         | 80/895 [32:43<4:04:57, 18.03s/it][A
  9%|‚ñâ         | 81/895 [33:03<4:10:32, 18.47s/it][A
  9%|‚ñâ         | 82/895 [33:22<4:12:54, 18.67s/it][A
  9%|‚ñâ         | 83/895 [33:38<4:04:00, 18.03s/it][A
  9%|‚ñâ         | 84/895 [34:00<4:17:17, 19.04s/it][A
  9%|‚ñâ         | 85/895 [34:13<3:54:45, 17.39s/it][A
 10%|‚ñâ         | 86/895 [34:30<3:50:06, 17.07s/it][A
 10%|‚ñâ         | 87/895 [34:43<3:37:07, 16.12s/it][Aslurmstepd: error: *** JOB 49171 ON puck5 CANCELLED AT 2025-10-15T10:35:17 ***
