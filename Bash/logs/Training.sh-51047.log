Running via sbatch on puck5 on Thu Nov 13 09:54:59 AM CET 2025
Python 3.10.13
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Appending key for api.wandb.ai to your netrc file: /home/tleludec/.netrc
wandb: Currently logged in as: tiphaine-leludec (tiphaine-leludec-ens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/wandb/run-20251113_095520-jojrabcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-deluge-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tiphaine-leludec-ens/whisper_lora
wandb: üöÄ View run at https://wandb.ai/tiphaine-leludec-ens/whisper_lora/runs/jojrabcx
Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.
trainable params: 491,520 || all params: 1,543,796,480 || trainable%: 0.0318
Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 297, in <module>
    trainer.train()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 2573, in _inner_training_loop
    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer_callback.py", line 506, in on_train_begin
    return self.call_event("on_train_begin", args, state, control)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer_callback.py", line 556, in call_event
    result = getattr(callback, event)(
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer_callback.py", line 752, in on_train_begin
    assert args.metric_for_best_model is not None, (
AssertionError: EarlyStoppingCallback requires metric_for_best_model to be defined
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33meager-deluge-37[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251113_095520-jojrabcx/logs[0m
computation end :Thu Nov 13 09:55:24 AM CET 2025
