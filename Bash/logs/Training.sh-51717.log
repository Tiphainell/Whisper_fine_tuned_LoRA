Running via sbatch on puck6 on Fri Nov 28 10:41:20 AM CET 2025
Python 3.10.13
==============================================
      Training with LoRA rank = 1
==============================================
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Appending key for api.wandb.ai to your netrc file: /home/tleludec/.netrc
wandb: Currently logged in as: tiphaine-leludec (tiphaine-leludec-ens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run umgkj2j3
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/Bash/wandb/run-20251128_104128-umgkj2j3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sponge-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tiphaine-leludec-ens/fine-tuning-whisper-lora
wandb: üöÄ View run at https://wandb.ai/tiphaine-leludec-ens/fine-tuning-whisper-lora/runs/umgkj2j3
The model is already on multiple devices. Skipping the move to device specified in `args`.
/home/tleludec/Transcription_whisper/Code/Data/Features_on_disk
Training with batch_size=8, lr=0.0001, num_epochs=30, lora_r=1
trainable params: 491,520 || all params: 1,543,796,480 || trainable%: 0.0318
Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script//src/Training.py", line 325, in <module>
    train(features_dir=features_dir, whisper_model=whisper_model, batch_size=batch_size,learning_rate=learning_rate,num_train_epochs=num_epochs, lora_r=lora_rank,lora_dropout=lora_dropout, lora_alpha=lora_alpha, target_modules=target_modules, test_eval=test_evaluation,output_dir=output_dir)
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script//src/Training.py", line 238, in train
    trainer.evaluate()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer_seq2seq.py", line 191, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4489, in evaluate
    output = eval_loop(
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4675, in evaluation_loop
    for step, inputs in enumerate(dataloader):
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/accelerate/data_loader.py", line 567, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script//src/Training.py", line 39, in __getitem__
    data = torch.load(self.files[idx])
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script//src/Training.py", line 325, in <module>
    train(features_dir=features_dir, whisper_model=whisper_model, batch_size=batch_size,learning_rate=learning_rate,num_train_epochs=num_epochs, lora_r=lora_rank,lora_dropout=lora_dropout, lora_alpha=lora_alpha, target_modules=target_modules, test_eval=test_evaluation,output_dir=output_dir)
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script//src/Training.py", line 238, in train
    trainer.evaluate()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer_seq2seq.py", line 191, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4489, in evaluate
    output = eval_loop(
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4675, in evaluation_loop
    for step, inputs in enumerate(dataloader):
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/accelerate/data_loader.py", line 567, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script//src/Training.py", line 39, in __getitem__
    data = torch.load(self.files[idx])
IndexError: list index out of range
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mdandy-sponge-10[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251128_104128-umgkj2j3/logs[0m
