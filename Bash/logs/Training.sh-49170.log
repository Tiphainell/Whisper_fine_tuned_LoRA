Running via sbatch on puck5 on Wed Oct 15 09:49:21 AM CEST 2025
Python 3.10.13
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
'(MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /openai/whisper-large/resolve/main/preprocessor_config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14bf1ca02bf0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: e839bcf7-0cbb-47b9-a31b-5f509ec0b853)')' thrown while requesting HEAD https://huggingface.co/openai/whisper-large/resolve/main/preprocessor_config.json
Retrying in 1s [Retry 1/5].
'(MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /openai/whisper-large/resolve/main/preprocessor_config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14bf1ca02ec0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: bc3be52f-481f-4894-945e-5ac053464882)')' thrown while requesting HEAD https://huggingface.co/openai/whisper-large/resolve/main/preprocessor_config.json
Retrying in 2s [Retry 2/5].
wandb: Appending key for api.wandb.ai to your netrc file: /home/tleludec/.netrc
wandb: Currently logged in as: tiphaine-leludec (tiphaine-leludec-ens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run i1un89nu
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/wandb/run-20251015_095004-i1un89nu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-serenity-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tiphaine-leludec-ens/whisper_lora
wandb: üöÄ View run at https://wandb.ai/tiphaine-leludec-ens/whisper_lora/runs/i1un89nu
trainable params: 491,520 || all params: 1,543,796,480 || trainable%: 0.0318
  0%|          | 0/8319 [00:00<?, ?it/s]/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.
  warnings.warn(
You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|          | 1/8319 [00:10<25:03:10, 10.84s/it]  0%|          | 2/8319 [00:17<19:16:11,  8.34s/it]  0%|          | 3/8319 [00:23<17:19:03,  7.50s/it]  0%|          | 4/8319 [00:30<16:02:15,  6.94s/it]  0%|          | 5/8319 [00:36<15:26:25,  6.69s/it]  0%|          | 6/8319 [00:43<15:48:12,  6.84s/it]  0%|          | 7/8319 [00:49<15:18:21,  6.63s/it]  0%|          | 8/8319 [00:56<15:32:53,  6.73s/it]  0%|          | 9/8319 [01:03<15:21:51,  6.66s/it]  0%|          | 10/8319 [01:09<15:27:10,  6.70s/it]Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 40, in __getitem__
    waveform, sr = torchaudio.load(audio_path)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 222, in load
    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/soundfile.py", line 27, in load
    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/soundfile_backend.py", line 221, in load
    with soundfile.SoundFile(filepath, "r") as file_:
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/soundfile.py", line 690, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/soundfile.py", line 1265, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening '/scratch1/data/raw_data/HD_PARK_HOSPITAL/audio/MICRO3/4CH025M.wav': Format not recognised.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 244, in <module>
    trainer.train()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 2618, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 5654, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/accelerate/data_loader.py", line 579, in __iter__
    next_batch = next(dataloader_iter)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 42, in __getitem__
    warnings.warn(f"[SKIP] Erreur de lecture pour {audio_path} : {e}")
NameError: name 'warnings' is not defined
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mgentle-serenity-24[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251015_095004-i1un89nu/logs[0m
computation end :Wed Oct 15 09:51:21 AM CEST 2025
