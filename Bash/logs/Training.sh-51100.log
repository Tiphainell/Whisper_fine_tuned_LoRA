Running via sbatch on puck5 on Thu Nov 13 03:50:20 PM CET 2025
Python 3.10.13
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Appending key for api.wandb.ai to your netrc file: /home/tleludec/.netrc
wandb: Currently logged in as: tiphaine-leludec (tiphaine-leludec-ens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run bvebkjvp
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/wandb/run-20251113_155041-bvebkjvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-dew-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tiphaine-leludec-ens/whisper_lora
wandb: üöÄ View run at https://wandb.ai/tiphaine-leludec-ens/whisper_lora/runs/bvebkjvp
Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.
trainable params: 491,520 || all params: 1,543,796,480 || trainable%: 0.0318
  0%|          | 0/8319 [00:00<?, ?it/s]/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.
  warnings.warn(
You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|          | 1/8319 [00:10<24:22:37, 10.55s/it]  0%|          | 2/8319 [00:17<18:48:42,  8.14s/it]  0%|          | 3/8319 [00:23<16:52:52,  7.31s/it]                                                     0%|          | 3/8319 [00:23<16:52:52,  7.31s/it]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']
{'loss': 3.4307, 'grad_norm': 0.9364316463470459, 'learning_rate': 0.0009997595864887606, 'epoch': 0.0}
Batch keys: ['input_features', 'labels']
Batch keys: ['input_features', 'labels']

  0%|          | 0/895 [00:00<?, ?it/s][A
  0%|          | 2/895 [00:25<3:07:51, 12.62s/it][A
  0%|          | 3/895 [00:40<3:24:11, 13.73s/it][A
  0%|          | 4/895 [01:08<4:45:03, 19.20s/it][A
  1%|          | 5/895 [01:26<4:34:04, 18.48s/it][A
  1%|          | 6/895 [01:50<5:03:21, 20.47s/it][A
  1%|          | 7/895 [02:12<5:07:52, 20.80s/it][A
  1%|          | 8/895 [02:35<5:22:04, 21.79s/it][A
  1%|          | 9/895 [02:47<4:36:08, 18.70s/it][A
  1%|          | 10/895 [02:58<3:58:05, 16.14s/it][A
  1%|          | 11/895 [03:13<3:53:12, 15.83s/it][A
  1%|‚ñè         | 12/895 [03:24<3:30:29, 14.30s/it][A
  1%|‚ñè         | 13/895 [03:38<3:29:08, 14.23s/it][A
  2%|‚ñè         | 14/895 [03:52<3:28:09, 14.18s/it][A
  2%|‚ñè         | 15/895 [04:12<3:53:29, 15.92s/it][A
  2%|‚ñè         | 16/895 [04:22<3:27:24, 14.16s/it][A
  2%|‚ñè         | 17/895 [04:37<3:30:58, 14.42s/it][A
  2%|‚ñè         | 18/895 [04:50<3:27:33, 14.20s/it][A
  2%|‚ñè         | 19/895 [05:08<3:40:18, 15.09s/it][A
  2%|‚ñè         | 20/895 [05:25<3:49:06, 15.71s/it][A
  2%|‚ñè         | 21/895 [05:40<3:48:08, 15.66s/it][A
  2%|‚ñè         | 22/895 [05:55<3:41:49, 15.25s/it][A
  3%|‚ñé         | 23/895 [06:11<3:46:36, 15.59s/it][A
  3%|‚ñé         | 24/895 [06:30<4:02:34, 16.71s/it][A
  3%|‚ñé         | 25/895 [08:09<10:00:52, 41.44s/it][A
  3%|‚ñé         | 26/895 [08:21<7:51:44, 32.57s/it] [A
  3%|‚ñé         | 27/895 [08:37<6:39:54, 27.64s/it][A
  3%|‚ñé         | 28/895 [08:52<5:44:13, 23.82s/it][A
  3%|‚ñé         | 29/895 [09:18<5:51:03, 24.32s/it][A
  3%|‚ñé         | 30/895 [09:31<5:00:30, 20.84s/it][A
  3%|‚ñé         | 31/895 [09:45<4:30:35, 18.79s/it][A
  4%|‚ñé         | 32/895 [09:59<4:10:12, 17.40s/it][A
  4%|‚ñé         | 33/895 [10:08<3:36:53, 15.10s/it][A
  4%|‚ñç         | 34/895 [10:18<3:11:56, 13.38s/it][A
  4%|‚ñç         | 35/895 [10:32<3:14:16, 13.55s/it][A
  4%|‚ñç         | 36/895 [10:47<3:22:24, 14.14s/it][A
  4%|‚ñç         | 37/895 [10:55<2:54:46, 12.22s/it][A
  4%|‚ñç         | 38/895 [11:08<2:59:01, 12.53s/it][A
  4%|‚ñç         | 39/895 [11:24<3:11:50, 13.45s/it][A
  4%|‚ñç         | 40/895 [11:31<2:45:47, 11.63s/it][A
  5%|‚ñç         | 41/895 [11:46<2:58:30, 12.54s/it][A
  5%|‚ñç         | 42/895 [12:08<3:39:16, 15.42s/it][A
  5%|‚ñç         | 43/895 [12:21<3:28:40, 14.70s/it][A
  5%|‚ñç         | 44/895 [12:34<3:22:25, 14.27s/it][A
  5%|‚ñå         | 45/895 [12:48<3:21:19, 14.21s/it][A
  5%|‚ñå         | 46/895 [13:01<3:12:46, 13.62s/it][A
  5%|‚ñå         | 47/895 [13:13<3:05:39, 13.14s/it][A
  5%|‚ñå         | 48/895 [13:27<3:09:23, 13.42s/it][A
  5%|‚ñå         | 49/895 [13:40<3:10:00, 13.48s/it][A
  6%|‚ñå         | 50/895 [13:53<3:07:02, 13.28s/it][A
  6%|‚ñå         | 51/895 [14:08<3:14:01, 13.79s/it][A
  6%|‚ñå         | 52/895 [14:22<3:15:16, 13.90s/it][A
  6%|‚ñå         | 53/895 [14:39<3:25:57, 14.68s/it][A
  6%|‚ñå         | 54/895 [14:52<3:18:44, 14.18s/it][A
  6%|‚ñå         | 55/895 [15:04<3:08:27, 13.46s/it][A
  6%|‚ñã         | 56/895 [15:20<3:20:06, 14.31s/it][A
  6%|‚ñã         | 57/895 [15:34<3:20:49, 14.38s/it][A
  6%|‚ñã         | 58/895 [15:47<3:12:20, 13.79s/it][A
  7%|‚ñã         | 59/895 [16:03<3:20:52, 14.42s/it][A
  7%|‚ñã         | 60/895 [16:16<3:13:47, 13.93s/it][A
  7%|‚ñã         | 61/895 [16:28<3:06:06, 13.39s/it][A
  7%|‚ñã         | 62/895 [16:41<3:04:51, 13.31s/it][A
  7%|‚ñã         | 63/895 [16:56<3:10:45, 13.76s/it][A
  7%|‚ñã         | 64/895 [17:13<3:24:13, 14.74s/it][A
  7%|‚ñã         | 65/895 [17:27<3:20:43, 14.51s/it][A
  7%|‚ñã         | 66/895 [17:39<3:13:13, 13.99s/it][A
  7%|‚ñã         | 67/895 [17:59<3:35:38, 15.63s/it][A
  8%|‚ñä         | 68/895 [18:14<3:32:51, 15.44s/it][A
  8%|‚ñä         | 69/895 [18:27<3:23:10, 14.76s/it][A
  8%|‚ñä         | 70/895 [18:39<3:13:00, 14.04s/it][A
  8%|‚ñä         | 71/895 [18:53<3:10:52, 13.90s/it][A
  8%|‚ñä         | 72/895 [19:07<3:10:08, 13.86s/it][A
  8%|‚ñä         | 73/895 [19:18<3:01:06, 13.22s/it][A
  8%|‚ñä         | 74/895 [19:32<3:01:24, 13.26s/it][A
  8%|‚ñä         | 75/895 [19:46<3:03:27, 13.42s/it][A
  8%|‚ñä         | 76/895 [19:58<2:59:43, 13.17s/it][A
  9%|‚ñä         | 77/895 [20:14<3:10:46, 13.99s/it][A
  9%|‚ñä         | 78/895 [20:28<3:09:34, 13.92s/it][A
  9%|‚ñâ         | 79/895 [20:37<2:50:40, 12.55s/it][A
  9%|‚ñâ         | 80/895 [20:53<3:02:08, 13.41s/it][A
  9%|‚ñâ         | 81/895 [21:09<3:12:10, 14.16s/it][A
  9%|‚ñâ         | 82/895 [21:26<3:26:45, 15.26s/it][A
  9%|‚ñâ         | 83/895 [21:41<3:24:56, 15.14s/it][A
  9%|‚ñâ         | 84/895 [22:01<3:44:14, 16.59s/it][A
  9%|‚ñâ         | 85/895 [22:13<3:25:30, 15.22s/it][A
 10%|‚ñâ         | 86/895 [22:27<3:19:50, 14.82s/it][A
 10%|‚ñâ         | 87/895 [22:39<3:07:57, 13.96s/it][A
 10%|‚ñâ         | 88/895 [22:58<3:26:00, 15.32s/it][A
 10%|‚ñâ         | 89/895 [23:13<3:25:52, 15.33s/it][A
 10%|‚ñà         | 90/895 [23:27<3:20:12, 14.92s/it][A
 10%|‚ñà         | 91/895 [23:37<3:02:31, 13.62s/it][A
 10%|‚ñà         | 92/895 [23:46<2:40:46, 12.01s/it][A
 10%|‚ñà         | 93/895 [23:56<2:35:39, 11.65s/it][A
 11%|‚ñà         | 94/895 [24:06<2:28:45, 11.14s/it][A
 11%|‚ñà         | 95/895 [24:16<2:22:17, 10.67s/it][A
 11%|‚ñà         | 96/895 [24:25<2:14:56, 10.13s/it][A
 11%|‚ñà         | 97/895 [24:35<2:15:34, 10.19s/it][A
 11%|‚ñà         | 98/895 [24:44<2:09:12,  9.73s/it][A
 11%|‚ñà         | 99/895 [24:54<2:12:18,  9.97s/it][A
 11%|‚ñà         | 100/895 [25:05<2:12:36, 10.01s/it][A
 11%|‚ñà‚ñè        | 101/895 [25:16<2:18:15, 10.45s/it][A
 11%|‚ñà‚ñè        | 102/895 [25:26<2:15:32, 10.26s/it][A
 12%|‚ñà‚ñè        | 103/895 [25:34<2:08:40,  9.75s/it][A
 12%|‚ñà‚ñè        | 104/895 [25:43<2:02:46,  9.31s/it][A
 12%|‚ñà‚ñè        | 105/895 [25:53<2:06:25,  9.60s/it][A
 12%|‚ñà‚ñè        | 106/895 [26:03<2:06:34,  9.63s/it][A
 12%|‚ñà‚ñè        | 107/895 [26:13<2:09:08,  9.83s/it][A
 12%|‚ñà‚ñè        | 108/895 [26:24<2:14:42, 10.27s/it][A
 12%|‚ñà‚ñè        | 109/895 [26:33<2:08:04,  9.78s/it][A
 12%|‚ñà‚ñè        | 110/895 [26:43<2:09:19,  9.88s/it][A
 12%|‚ñà‚ñè        | 111/895 [26:53<2:08:26,  9.83s/it][A
 13%|‚ñà‚ñé        | 112/895 [27:08<2:31:29, 11.61s/it][A
 13%|‚ñà‚ñé        | 113/895 [27:31<3:12:34, 14.78s/it][A
 13%|‚ñà‚ñé        | 114/895 [27:52<3:37:49, 16.73s/it][A
 13%|‚ñà‚ñé        | 115/895 [28:11<3:47:47, 17.52s/it][A
 13%|‚ñà‚ñé        | 116/895 [28:33<4:02:36, 18.69s/it][A
 13%|‚ñà‚ñé        | 117/895 [28:59<4:30:56, 20.90s/it][A
 13%|‚ñà‚ñé        | 118/895 [29:24<4:46:45, 22.14s/it][A
 13%|‚ñà‚ñé        | 119/895 [29:51<5:07:26, 23.77s/it][A
 13%|‚ñà‚ñé        | 120/895 [30:12<4:54:53, 22.83s/it][A
 14%|‚ñà‚ñé        | 121/895 [30:29<4:33:15, 21.18s/it][A
 14%|‚ñà‚ñé        | 122/895 [30:52<4:37:10, 21.51s/it][A
 14%|‚ñà‚ñé        | 123/895 [31:06<4:08:14, 19.29s/it][Aslurmstepd: error: *** JOB 51100 ON puck5 CANCELLED AT 2025-11-13T16:22:48 ***
