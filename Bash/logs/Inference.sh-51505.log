Running via sbatch on puck6 on Fri Nov 21 10:51:27 AM CET 2025
Python 3.10.13
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(

 Loading Base model...
Inference:   0%|          | 0/740 [00:00<?, ?it/s]Inference:   0%|          | 0/740 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/inference.py", line 157, in <module>
    base_preds, base_refs, filenames = run_inference(base_model, processor, dataloader, device)
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/inference.py", line 75, in run_inference
    for batch in tqdm(dataloader, desc="Inference"):
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/inference.py", line 48, in collate_fn
    labels = torch.stack([b["labels"] for b in batch])
RuntimeError: stack expects each tensor to be equal size, but got [6] at entry 0 and [4] at entry 3
computation end :Fri Nov 21 10:51:45 AM CET 2025
