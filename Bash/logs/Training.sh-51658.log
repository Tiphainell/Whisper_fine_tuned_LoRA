Running via sbatch on puck6 on Tue Nov 25 04:43:44 PM CET 2025
Python 3.10.13
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Appending key for api.wandb.ai to your netrc file: /home/tleludec/.netrc
wandb: Currently logged in as: tiphaine-leludec (tiphaine-leludec-ens) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run m3aleat5
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/wandb/run-20251125_164352-m3aleat5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-serenity-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tiphaine-leludec-ens/fine-tuning-whisper-lora
wandb: üöÄ View run at https://wandb.ai/tiphaine-leludec-ens/fine-tuning-whisper-lora/runs/m3aleat5
The model is already on multiple devices. Skipping the move to device specified in `args`.
/home/tleludec/Transcription_whisper/Code/Data/Features_on_disk
Training with batch_size=8, lr=1e-4, num_epochs=30, lora_r=1
trainable params: 491,520 || all params: 1,543,796,480 || trainable%: 0.0318
Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 312, in <module>
    train(features_dir=features_dir, whisper_model=whisper_model, batch_size=batch_size,learning_rate=learning_rate,num_train_epochs=num_epochs, lora_r=lora_rank,lora_dropout=lora_dropout, lora_alpha=lora_alpha, test_eval=test_evaluation,output_dir=output_dir)
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 235, in train
    trainer.evaluate()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer_seq2seq.py", line 191, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4489, in evaluate
    output = eval_loop(
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4675, in evaluation_loop
    for step, inputs in enumerate(dataloader):
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/accelerate/data_loader.py", line 567, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 37, in __getitem__
    data = torch.load(self.files[idx])
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 312, in <module>
    train(features_dir=features_dir, whisper_model=whisper_model, batch_size=batch_size,learning_rate=learning_rate,num_train_epochs=num_epochs, lora_r=lora_rank,lora_dropout=lora_dropout, lora_alpha=lora_alpha, test_eval=test_evaluation,output_dir=output_dir)
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 235, in train
    trainer.evaluate()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer_seq2seq.py", line 191, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4489, in evaluate
    output = eval_loop(
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 4675, in evaluation_loop
    for step, inputs in enumerate(dataloader):
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/accelerate/data_loader.py", line 567, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 416, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 37, in __getitem__
    data = torch.load(self.files[idx])
IndexError: list index out of range
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mgenial-serenity-3[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251125_164352-m3aleat5/logs[0m
computation end :Tue Nov 25 04:44:04 PM CET 2025
