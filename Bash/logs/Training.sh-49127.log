Running via sbatch on puck5 on Tue Oct 14 03:56:12 PM CEST 2025Python 3.10.13/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.  warnings.warn(/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.  warnings.warn(wandb: Appending key for api.wandb.ai to your netrc file: /home/tleludec/.netrcwandb: Currently logged in as: tiphaine-leludec (tiphaine-leludec-ens) to https://api.wandb.ai. Use `wandb login --relogin` to force reloginwandb: setting up run ob3fd8y7wandb: Tracking run with wandb version 0.22.2wandb: Run data is saved locally in /home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/wandb/run-20251014_155632-ob3fd8y7wandb: Run `wandb offline` to turn off syncing.wandb: Syncing run firm-mountain-22wandb: ‚≠êÔ∏è View project at https://wandb.ai/tiphaine-leludec-ens/whisper_lorawandb: üöÄ View run at https://wandb.ai/tiphaine-leludec-ens/whisper_lora/runs/ob3fd8y7trainable params: 491,520 || all params: 1,543,796,480 || trainable%: 0.0318  0%|          | 0/8319 [00:00<?, ?it/s]/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.  warnings.warn(You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding./home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.  return fn(*args, **kwargs)/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None  warnings.warn(/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")  0%|          | 1/8319 [00:09<21:15:09,  9.20s/it]  0%|          | 2/8319 [00:15<17:46:25,  7.69s/it]  0%|          | 3/8319 [00:22<16:29:48,  7.14s/it]  0%|          | 4/8319 [00:28<15:52:51,  6.88s/it]  0%|          | 5/8319 [00:35<15:37:10,  6.76s/it]  0%|          | 6/8319 [00:42<15:53:23,  6.88s/it]  0%|          | 7/8319 [00:48<15:19:55,  6.64s/it]  0%|          | 8/8319 [00:55<15:21:12,  6.65s/it]  0%|          | 9/8319 [01:01<15:15:47,  6.61s/it]  0%|          | 10/8319 [01:08<15:27:08,  6.69s/it]Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Batch keys: ['input_features', 'labels']Traceback (most recent call last):  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 194, in <module>    trainer.train()  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train    return inner_training_loop(  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 2618, in _inner_training_loop    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/transformers/trainer.py", line 5654, in get_batch_samples    batch_samples.append(next(epoch_iterator))  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/accelerate/data_loader.py", line 579, in __iter__    next_batch = next(dataloader_iter)  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__    data = self._next_data()  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch    data = [self.dataset[idx] for idx in possibly_batched_index]  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>    data = [self.dataset[idx] for idx in possibly_batched_index]  File "/home/tleludec/Transcription_whisper/Code/fine-tuning-whisper/Script/dataset_hugging_face.py", line 32, in __getitem__    waveform, sr = torchaudio.load(audio_path)  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/utils.py", line 222, in load    return backend.load(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/soundfile.py", line 27, in load    return soundfile_backend.load(uri, frame_offset, num_frames, normalize, channels_first, format)  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/torchaudio/_backend/soundfile_backend.py", line 221, in load    with soundfile.SoundFile(filepath, "r") as file_:  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/soundfile.py", line 690, in __init__    self._file = self._open(file, mode_int, closefd)  File "/home/tleludec/Transcription_whisper/venv_oberon/lib/python3.10/site-packages/soundfile.py", line 1265, in _open    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))soundfile.LibsndfileError: Error opening '/scratch1/data/raw_data/HD_PARK_HOSPITAL/audio/MICRO3/4CH025M.wav': Format not recognised.[1;34mwandb[0m: [1;34mwandb[0m: üöÄ View run [33mfirm-mountain-22[0m at: [34m[0m[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251014_155632-ob3fd8y7/logs[0mcomputation end :Tue Oct 14 03:57:48 PM CEST 2025